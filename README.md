# Rakuten MLOps - Incremental Data Pipeline

Pipeline de donnÃ©es incrÃ©mentales pour le projet Rakuten avec MLflow tracking, PostgreSQL et Airflow orchestration.

## ğŸ“‹ Architecture

Ce projet implÃ©mente une architecture data-centric MLOps avec :

- **PostgreSQL** : Stockage des donnÃ©es avec audit trail complet
- **MLflow** : Versioning des datasets et modÃ¨les
- **Airflow** : Orchestration hebdomadaire du pipeline
- **Random Oversampling** : Balancing des classes pour donnÃ©es dÃ©sÃ©quilibrÃ©es

### Pipeline Flow

```
Raw CSV (40% â†’ 100%) â†’ PostgreSQL â†’ Balanced Dataset â†’ MLflow â†’ Model
```

Pour plus de dÃ©tails, voir [`docs/ARCHITECTURE_PLAN.md`](docs/ARCHITECTURE_PLAN.md)

## ğŸš€ Quick Start

### PrÃ©requis

- Docker & Docker Compose
- Python 3.11+
- DonnÃ©es brutes dans `data/raw/` (X_train.csv, Y_train.csv, X_test.csv, images/)

### 1. Configuration

CrÃ©er un fichier `.env` Ã  partir de l'exemple :

```bash
cp env.example.txt .env
```

Ã‰diter `.env` et configurer les mots de passe :

```bash
POSTGRES_PASSWORD=votre_mot_de_passe
AIRFLOW_PASSWORD=votre_mot_de_passe_airflow
```

### 2. DÃ©marrer l'infrastructure

```bash
# DÃ©marrer tous les services
docker-compose up -d

# VÃ©rifier que tous les services sont lancÃ©s
docker-compose ps
```

Services disponibles :
- **PostgreSQL** : `localhost:5432`
- **MLflow UI** : http://localhost:5000
- **Airflow UI** : http://localhost:8080 (admin/admin)

### 3. Initialiser la base de donnÃ©es

```bash
# Dans le container Airflow
docker exec -it rakuten_airflow_webserver bash

# Installer les dÃ©pendances
pip install -r /requirements.txt

# Initialiser la base avec 40% des donnÃ©es
python /opt/airflow/src/data/db_init.py
```

### 4. Tester le pipeline

```bash
# Charger les 3% suivants
python /opt/airflow/src/data/loader.py

# GÃ©nÃ©rer un dataset balancÃ©
python /opt/airflow/src/data/dataset_generator.py

# VÃ©rifier l'Ã©tat
python /opt/airflow/src/data/loader.py --status
```

### 5. Activer le DAG Airflow

1. Aller sur http://localhost:8080
2. Se connecter (admin/admin)
3. Activer le DAG `weekly_ml_pipeline`
4. DÃ©clencher manuellement ou attendre l'exÃ©cution hebdomadaire

## ğŸ“‚ Structure du Projet

```
.
â”œâ”€â”€ docker-compose.yml          # Infrastructure Docker
â”œâ”€â”€ env.example.txt             # Variables d'environnement (exemple)
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ ARCHITECTURE_PLAN.md    # Plan d'architecture dÃ©taillÃ©
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py               # Configuration centralisÃ©e
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ schema.sql          # SchÃ©ma PostgreSQL
â”‚       â”œâ”€â”€ db_init.py          # Initialisation DB (40%)
â”‚       â”œâ”€â”€ loader.py           # Chargement incrÃ©mental
â”‚       â””â”€â”€ dataset_generator.py # GÃ©nÃ©ration datasets balancÃ©s
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ weekly_ml_pipeline_dag.py # DAG Airflow
â””â”€â”€ data/
    â”œâ”€â”€ raw/                    # DonnÃ©es brutes (gitignored)
    â””â”€â”€ training_snapshots/     # Datasets gÃ©nÃ©rÃ©s (gitignored)
```

## ğŸ”„ Workflow

### Pipeline Hebdomadaire

Le DAG Airflow s'exÃ©cute chaque lundi Ã  minuit et effectue :

1. **Check State** : VÃ©rifier le pourcentage actuel
2. **Load Data** : Charger +3% de donnÃ©es (40% â†’ 43% â†’ 46% ...)
3. **Validate** : VÃ©rifier que les donnÃ©es sont correctement chargÃ©es
4. **Generate Dataset** : CrÃ©er un dataset balancÃ© via random oversampling
5. **Log to MLflow** : Versionner le dataset dans MLflow
6. **Train Model** : DÃ©clencher l'entraÃ®nement (TODO)
7. **Notify** : Envoyer un rÃ©sumÃ© de l'exÃ©cution

Les conteneurs Docker (PostgreSQL, Airflow, MLflow) doivent rester actifs pour que le DAG tourne ; si l'infra est arrÃªtÃ©e ou le Mac/PC passe en veille, le scheduler ne peut pas progresser. En cas d'interruption, relancer `docker-compose up -d`, vÃ©rifier que les services sont "Up" puis, en dÃ©pannage, dÃ©clencher manuellement `weekly_ml_pipeline` depuis l'UI ou avec `docker exec -it rakuten_airflow_webserver airflow dags trigger weekly_ml_pipeline`.

### Commandes Utiles

```bash
# VÃ©rifier l'Ã©tat actuel
python src/data/loader.py --status

# Voir l'historique des chargements
python src/data/loader.py --history

# Charger manuellement jusqu'Ã  un certain %
python src/data/loader.py --percentage 50

# GÃ©nÃ©rer un dataset balancÃ©
python src/data/dataset_generator.py

# Tester la configuration
python src/config.py
```

## ğŸ—„ï¸ Base de DonnÃ©es

### Tables Principales

- **`products`** : Produits (Ã©tat actuel)
- **`labels`** : Labels des produits
- **`products_history`** : Audit trail (toutes les modifications)
- **`data_loads`** : Historique des chargements

### RequÃªtes Utiles

```sql
-- Ã‰tat actuel
SELECT * FROM current_data_state;

-- Distribution des classes
SELECT * FROM class_distribution;

-- Historique des chargements
SELECT batch_name, percentage, total_rows, status, completed_at 
FROM data_loads 
ORDER BY completed_at DESC;

-- Produits ajoutÃ©s Ã  une date donnÃ©e
SELECT COUNT(*) FROM products_history 
WHERE load_batch_id = (SELECT id FROM data_loads WHERE batch_name = 'week_1');
```

## ğŸ“Š MLflow

### Experiments

- **`rakuten_dataset_versioning`** : Datasets gÃ©nÃ©rÃ©s
- **`rakuten_model_training`** : ModÃ¨les entraÃ®nÃ©s (TODO)

### AccÃ©der Ã  MLflow

```bash
# UI Web
open http://localhost:5000

# Lister les experiments
mlflow experiments list --tracking-uri http://localhost:5000

# Voir les runs d'un experiment
mlflow runs list --experiment-name rakuten_dataset_versioning
```

## ğŸ§ª Tests

```bash
# Tests unitaires (TODO)
pytest tests/

# Tests d'intÃ©gration (TODO)
pytest tests/integration/
```

## ğŸ”§ DÃ©veloppement Local

```bash
# CrÃ©er un environnement virtuel
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt

# Configurer les variables d'environnement pour dÃ©veloppement local
export POSTGRES_HOST=localhost
export MLFLOW_TRACKING_URI=http://localhost:5000
export DATA_PATH=$(pwd)/data/raw
export ENVIRONMENT=local
```

## ğŸ“ Logs

```bash
# Logs Airflow
docker logs rakuten_airflow_scheduler
docker logs rakuten_airflow_webserver

# Logs PostgreSQL
docker logs rakuten_postgres

# Logs MLflow
docker logs rakuten_mlflow
```

## ğŸ›‘ ArrÃªter les Services

```bash
# ArrÃªter tous les services
docker-compose down

# ArrÃªter et supprimer les volumes (attention : perte de donnÃ©es !)
docker-compose down -v
```

## ğŸ› Troubleshooting

### ProblÃ¨me : Cannot connect to PostgreSQL

```bash
# VÃ©rifier que le service est lancÃ©
docker-compose ps postgres

# VÃ©rifier les logs
docker logs rakuten_postgres

# RedÃ©marrer le service
docker-compose restart postgres
```

### ProblÃ¨me : Airflow DAG n'apparaÃ®t pas

```bash
# VÃ©rifier la syntaxe du DAG
docker exec -it rakuten_airflow_webserver airflow dags list

# VÃ©rifier les erreurs
docker exec -it rakuten_airflow_webserver airflow dags list-import-errors
```

### ProblÃ¨me : MLflow ne track pas les runs

```bash
# VÃ©rifier la connexion Ã  MLflow
curl http://localhost:5000/health

# VÃ©rifier les logs
docker logs rakuten_mlflow
```

## ğŸ“š Documentation ComplÃ¨te

- [Plan d'Architecture](docs/ARCHITECTURE_PLAN.md)
- [SchÃ©ma de Base de DonnÃ©es](src/data/schema.sql)
- [Configuration](src/config.py)

## ğŸ‘¥ Contributeurs

Projet rÃ©alisÃ© dans le cadre de la formation DataScientest MLOps (septembre 2025).

## ğŸ“„ License

Voir [LICENSE](LICENSE)
