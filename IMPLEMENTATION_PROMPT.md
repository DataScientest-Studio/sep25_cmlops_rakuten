# Prompt d'Impl√©mentation - Pipeline MLOps Automatis√©

## Contexte du Projet

Je travaille sur un projet MLOps de classification de produits Rakuten. Le repository contient d√©j√† une infrastructure fonctionnelle avec:
- PostgreSQL avec audit trail
- MLflow pour le tracking
- FastAPI pour le serving
- Prometheus + Grafana pour le monitoring
- Interface Streamlit pour le contr√¥le

**√âtat actuel:** Toutes les op√©rations (chargement de donn√©es, entra√Ænement, promotion) sont manuelles via Streamlit ou scripts.

**Objectif:** Automatiser le pipeline complet selon le workflow suivant:
1. **Chargement hebdomadaire automatique** de +3% des donn√©es
2. **Re-entra√Ænement automatique** apr√®s chaque chargement
3. **Promotion conditionnelle** du mod√®le si F1 > seuil (ex: 0.75)
4. **Monitoring continu** du mod√®le en production
5. **D√©tection de drift** automatique
6. **Syst√®me d'alertes** si drift important
7. **Interface de d√©cision humaine** pour les actions correctives

---

## T√¢ches √† Impl√©menter

### Phase 1: Orchestration Hebdomadaire (Priorit√©: HAUTE)

**Objectif:** Mettre en place un scheduler qui d√©clenche automatiquement le chargement de donn√©es chaque semaine.

**Options possibles:**
- Option A: Airflow (plus robuste, UI built-in)
- Option B: Prefect (moderne, plus simple)
- Option C: Cron + Python script (minimaliste)

**Ce que je dois faire:**
1. Choisir la solution d'orchestration adapt√©e au projet
2. Cr√©er un DAG/Flow/Script qui:
   - S'ex√©cute chaque lundi √† 2h du matin (configurable)
   - Appelle le script de chargement de donn√©es (+3%)
   - V√©rifie que le chargement s'est bien pass√©
   - Log les r√©sultats
3. Dockeriser la solution d'orchestration
4. L'int√©grer au `docker-compose.yml`
5. Ajouter les commandes au `Makefile`

**Fichiers √† cr√©er/modifier:**
- `orchestration/scheduler.py` ou `orchestration/dags/weekly_pipeline.py`
- `docker-compose.yml` (ajouter service orchestrateur)
- `Dockerfile.orchestrator` (si n√©cessaire)
- `Makefile` (nouvelles commandes)

---

### Phase 2: Pipeline d'Entra√Ænement Automatique (Priorit√©: HAUTE)

**Objectif:** Apr√®s chaque chargement de donn√©es, d√©clencher automatiquement un entra√Ænement.

**Ce que je dois faire:**
1. Cr√©er un script `scripts/auto_train.py` qui:
   - D√©tecte qu'il y a de nouvelles donn√©es dans PostgreSQL
   - G√©n√®re un dataset balanc√© automatiquement
   - Lance l'entra√Ænement avec les hyperparam√®tres par d√©faut
   - Log tout dans MLflow avec tags sp√©cifiques (ex: `auto_trained=true`)
   - Retourne le run_id du nouveau mod√®le

2. Int√©grer ce script dans le workflow de l'orchestrateur:
   - Task 1: Load data (+3%)
   - Task 2: Auto train (d√©pend de Task 1)
   - Task 3: Evaluate model (d√©pend de Task 2)

3. G√©rer les erreurs et retry logic

**Fichiers √† cr√©er/modifier:**
- `scripts/auto_train.py`
- `src/models/auto_trainer.py` (classe pour l'entra√Ænement automatis√©)
- Mise √† jour du DAG/Flow d'orchestration

---

### Phase 3: Promotion Automatique Conditionnelle (Priorit√©: HAUTE)

**Objectif:** Promouvoir automatiquement le nouveau mod√®le en production si ses performances d√©passent un seuil.

**Ce que je dois faire:**
1. Cr√©er un script `scripts/auto_promote.py` qui:
   - R√©cup√®re les m√©triques du nouveau mod√®le depuis MLflow
   - Compare avec le mod√®le actuellement en production
   - D√©cide de la promotion selon les r√®gles:
     - Si F1_nouveau > 0.75 ET F1_nouveau > F1_production ‚Üí PROMOTE
     - Sinon ‚Üí ARCHIVE (stage="None" dans MLflow)
   - Log la d√©cision dans MLflow avec justification
   - Si promotion, archive l'ancien mod√®le en stage "Archived"

2. Ajouter des notifications (optionnel mais recommand√©):
   - Email/Slack si promotion effectu√©e
   - Log dans un fichier de d√©cisions

3. Int√©grer dans le workflow orchestr√©:
   - Task 4: Auto promote (d√©pend de Task 3)

**Fichiers √† cr√©er/modifier:**
- `scripts/auto_promote.py`
- `src/models/promotion_engine.py`
- Configuration des seuils dans `.env` ou `config.yaml`

**Variables de configuration √† ajouter:**
```env
AUTO_PROMOTION_ENABLED=true
MIN_F1_THRESHOLD=0.75
PROMOTION_METRIC=weighted_f1
NOTIFICATION_EMAIL=team@example.com
NOTIFICATION_SLACK_WEBHOOK=https://...
```

---

### Phase 4: Monitoring et D√©tection de Drift (Priorit√©: MOYENNE)

**Objectif:** D√©tecter automatiquement quand le mod√®le en production se d√©grade ou que les donn√©es d√©rivent.

**Ce que je dois faire:**
1. Am√©liorer le syst√®me de monitoring existant:
   - Collecter plus de m√©triques dans `inference_log.csv`
   - Calculer des statistiques sur fen√™tres glissantes (7 jours, 30 jours)

2. Cr√©er un module de d√©tection de drift `src/monitoring/drift_monitor.py`:
   - **Data Drift:** Comparer distribution des inputs (longueur texte, vocabulaire)
   - **Prediction Drift:** Analyser distribution des pr√©dictions
   - **Performance Drift:** Simuler avec des donn√©es de test
   - Utiliser des tests statistiques (Kolmogorov-Smirnov, PSI)

3. Cr√©er un job p√©riodique (quotidien) qui:
   - Ex√©cute l'analyse de drift
   - Calcule des scores de drift
   - Compare aux seuils configur√©s
   - Sauvegarde les r√©sultats dans PostgreSQL (table `drift_reports`)

4. Ajouter un dashboard Grafana pour visualiser le drift

**Fichiers √† cr√©er/modifier:**
- `src/monitoring/drift_monitor.py`
- `src/monitoring/statistical_tests.py`
- `orchestration/dags/daily_drift_check.py` (nouveau DAG quotidien)
- `src/data/schema.sql` (ajouter table `drift_reports`)
- `grafana/dashboards/drift_monitoring.json`

**Sch√©ma de la table drift_reports:**
```sql
CREATE TABLE drift_reports (
    id SERIAL PRIMARY KEY,
    report_date TIMESTAMP NOT NULL,
    data_drift_score FLOAT,
    prediction_drift_score FLOAT,
    performance_drift_score FLOAT,
    drift_detected BOOLEAN,
    details JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);
```

---

### Phase 5: Syst√®me d'Alertes (Priorit√©: MOYENNE)

**Objectif:** Notifier l'√©quipe quand un drift important est d√©tect√©.

**Ce que je dois faire:**
1. Cr√©er un syst√®me d'alertes `src/monitoring/alerting.py`:
   - V√©rifier les seuils de drift
   - Si drift_score > seuil critique:
     - Envoyer email √† l'√©quipe
     - Poster sur Slack
     - Cr√©er une alerte dans Grafana
     - Logger l'√©v√©nement

2. D√©finir les niveaux d'alerte:
   - WARNING: drift_score > 0.1 ‚Üí Log seulement
   - ALERT: drift_score > 0.2 ‚Üí Email + Slack
   - CRITICAL: drift_score > 0.3 ‚Üí Email + Slack + Page on-call

3. Int√©grer dans le workflow quotidien de drift detection

**Fichiers √† cr√©er/modifier:**
- `src/monitoring/alerting.py`
- `src/monitoring/notification_channels.py` (email, Slack, etc.)
- Configuration dans `.env`

**Variables de configuration:**
```env
ALERT_ENABLED=true
ALERT_EMAIL_FROM=mlops@example.com
ALERT_EMAIL_TO=team@example.com
ALERT_SLACK_WEBHOOK=https://hooks.slack.com/...
DRIFT_WARNING_THRESHOLD=0.1
DRIFT_ALERT_THRESHOLD=0.2
DRIFT_CRITICAL_THRESHOLD=0.3
```

---

### Phase 6: Interface de D√©cision Humaine (Priorit√©: BASSE)

**Objectif:** Permettre √† l'√©quipe de prendre des d√©cisions quand une alerte est d√©clench√©e.

**Ce que je dois faire:**
1. Ajouter une nouvelle page Streamlit `pages/5_Alerts_Dashboard.py`:
   - Afficher les alertes r√©centes
   - D√©tails du drift d√©tect√© (graphiques, m√©triques)
   - Actions disponibles:
     - "Forcer un re-entra√Ænement maintenant"
     - "Investiguer - Ne rien faire"
     - "Ajuster les seuils d'alerte"
     - "Rollback au mod√®le pr√©c√©dent"
   - Historique des d√©cisions prises

2. Cr√©er une API de contr√¥le dans FastAPI:
   - `POST /api/trigger-retrain` (force un re-entra√Ænement)
   - `POST /api/rollback-model` (rollback)
   - `GET /api/alerts` (liste des alertes)
   - `POST /api/alerts/{id}/acknowledge` (marquer comme trait√©)

3. Sauvegarder les actions humaines dans PostgreSQL pour audit

**Fichiers √† cr√©er/modifier:**
- `streamlit_app/pages/5_Alerts_Dashboard.py`
- `src/serve/routes.py` (ajouter routes de contr√¥le)
- `src/data/schema.sql` (table `alert_actions`)

---

### Phase 7: Tests et Documentation (Priorit√©: MOYENNE)

**Ce que je dois faire:**
1. √âcrire des tests pour les nouveaux composants:
   - Tests unitaires pour `auto_train.py`
   - Tests unitaires pour `auto_promote.py`
   - Tests unitaires pour `drift_monitor.py`
   - Tests d'int√©gration pour le workflow complet

2. Mettre √† jour la documentation:
   - `README.md` avec les nouvelles commandes
   - Documentation des DAGs/Flows
   - Guide de r√©ponse aux alertes
   - Runbook pour les incidents

3. Cr√©er des fixtures et donn√©es de test

**Fichiers √† cr√©er:**
- `tests/test_auto_train.py`
- `tests/test_auto_promote.py`
- `tests/test_drift_monitor.py`
- `tests/test_alerting.py`
- `docs/ALERTING_GUIDE.md`
- `docs/RUNBOOK.md`

---

## Plan d'Impl√©mentation Recommand√©

### Sprint 1 (1-2 semaines): Orchestration de Base
- ‚úÖ Phase 1: Orchestration hebdomadaire
- ‚úÖ Phase 2: Pipeline d'entra√Ænement automatique
- üéØ Livrable: Pipeline qui load data + train automatiquement chaque semaine

### Sprint 2 (1 semaine): Promotion Automatique
- ‚úÖ Phase 3: Promotion conditionnelle
- üéØ Livrable: Mod√®les promus automatiquement si performances OK

### Sprint 3 (1-2 semaines): Monitoring et Alertes
- ‚úÖ Phase 4: D√©tection de drift
- ‚úÖ Phase 5: Syst√®me d'alertes
- üéØ Livrable: Alertes automatiques en cas de drift

### Sprint 4 (1 semaine): Interface et Polish
- ‚úÖ Phase 6: Interface de d√©cision
- ‚úÖ Phase 7: Tests et documentation
- üéØ Livrable: Syst√®me complet et document√©

---

## Questions √† Clarifier Avant de Commencer

1. **Orchestration:** Pr√©f√©rence entre Airflow, Prefect ou Cron? (Recommandation: Airflow pour la robustesse)

2. **Notifications:** Avez-vous d√©j√† un Slack workspace? Une adresse email SMTP configur√©e?

3. **Seuils:** Quels seuils de performance et de drift souhaitez-vous utiliser?
   - F1 minimum pour promotion: 0.75?
   - Drift warning threshold: 0.1?
   - Drift alert threshold: 0.2?

4. **Fr√©quence:** Confirmation du schedule:
   - Chargement data: Hebdomadaire (lundi 2h)?
   - Drift check: Quotidien (tous les jours 1h)?

5. **Ressources:** Combien de temps de calcul est acceptable pour un entra√Ænement? (pour ajuster les timeouts)

---

## Commandes Make √† Ajouter

```makefile
# Orchestration
start-orchestrator    # D√©marrer l'orchestrateur
stop-orchestrator     # Arr√™ter l'orchestrateur
logs-orchestrator     # Voir les logs

# Auto training
trigger-auto-train    # Forcer un entra√Ænement maintenant
trigger-auto-promote  # Forcer une √©valuation de promotion

# Monitoring
check-drift           # Ex√©cuter manuellement le drift check
view-alerts           # Afficher les alertes r√©centes
clear-alerts          # Marquer toutes les alertes comme vues

# Tests
test-pipeline         # Tester le pipeline complet
test-integration      # Tests d'int√©gration
```

---

## Technologies Sugg√©r√©es

**Pour l'orchestration:**
- Apache Airflow 2.8+ (robuste, UI compl√®te, large communaut√©)
- OU Prefect 2.0+ (plus moderne, plus simple)

**Pour les alertes:**
- Python `smtplib` pour les emails
- `slack-sdk` pour Slack
- Grafana Alerting pour les dashboards

**Pour le drift detection:**
- `scipy.stats` pour les tests statistiques
- `alibi-detect` (optionnel, library sp√©cialis√©e)
- Custom implementation simple

**Pour le stockage:**
- PostgreSQL (d√©j√† en place) pour les rapports et audit
- MLflow (d√©j√† en place) pour les mod√®les et m√©triques

---

## Prompt √† Utiliser avec l'Assistant

```
Je veux impl√©menter le pipeline MLOps automatis√© d√©crit dans IMPLEMENTATION_PROMPT.md.

Commen√ßons par la Phase 1: Orchestration Hebdomadaire.

Je souhaite utiliser [Airflow/Prefect/Cron] comme solution d'orchestration.

Aide-moi √†:
1. Cr√©er la structure de fichiers n√©cessaire
2. √âcrire le code du DAG/Flow/Script
3. Configurer le service dans docker-compose.yml
4. Tester que √ßa fonctionne

Proc√®de √©tape par √©tape et attends ma validation avant de passer √† l'√©tape suivante.
```

---

## Notes Importantes

- Garder le code simple et maintenable
- Privil√©gier la robustesse √† la complexit√©
- Logger abondamment pour faciliter le debug
- Penser √† la s√©curit√© (pas de secrets en dur, utiliser .env)
- Tester chaque composant individuellement avant l'int√©gration
- Documenter au fur et √† mesure

---

**Statut:** Pr√™t √† commencer l'impl√©mentation
**Date de cr√©ation:** 2026-02-17
**Derni√®re mise √† jour:** 2026-02-17
